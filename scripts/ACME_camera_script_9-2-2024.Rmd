---
title: "ACME camera script 9-2-2024"
author: "Marissa A. Dyck"
date: "2024-02-09"
output: 
  html_document:
    code_folding: show
    theme: journal
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
```

## Before you begin

A few notes about this script.

If you are running this with the 2022-2023 data make sure you download the whole (OSM_2022-2023 GitHub repository)[https://github.com/ACMElabUvic/OSM_2022-2023] from the ACMElabUvic GitHub. This will ensure you have all the files, data, and proper folder structure you will need to run this code and associated analyses.

Also make sure you open RStudio through the R project (OSM_2022-2023.Rproj) this will automatically set your working directory to the correct place (wherever you saved the repository) and ensure you don't have to change the file paths for some of the data. 

If you have question please email the most recent author, currently   

Marissa A. Dyck   
Postdoctoral research fellow    
University of Victoria    
School of Environmental Studies     
Email: [marissadyck@uvic.ca](mailto:marissadyck@uvic.ca)     


## Install packages

If you don't already have the following packages installed, use the code below to install them.

```{r install packages, eval=FALSE}

# install packages ----------------------

install.packages(tidyverse) # data tidying, visualization, much more
install.packages(withr) # used to temporarily set wd
```


## Load libraries

Then load the packages to your library.

```{r libraries}

# libraries ----------------------

library(tidyverse) # will load all tidyverse packages, can see complete list using tidyverse_packages()
library(withr)
```


## Import data

If you opened the OSM_2022-2023.Rproj file you should have your working directory set to the GitHub repository that you downloaded to your hard drive.

We need to temporarily set your working drive to the ACME lab Netdrive to import the Timelapse data files (there are too many to efficiently store on GitHub each year). We will use the `with_dir()` function in the *withr* package to do this. 

Helpful instructions for connecting to and navigating the Netdrive can also be found here: [https://docs.google.com/document/d/1Z72IrlIXO8MUHCoVztcMrMdL10R2tHrHThEgfow1Cu0/edit ](https://docs.google.com/document/d/1Z72IrlIXO8MUHCoVztcMrMdL10R2tHrHThEgfow1Cu0/edit).


### Timelapse data option 1

This code will import all of the timelapse data files and merge them into one data frame.

Make a list of all the data files and use `map_drf()` to read them in and join them to one data frame (map is a function in the *purrr* package that performs iterations and map_dfr returns data frames by row-binding objects together).

```{r import timelapse data option 1, message=FALSE, warning=FALSE}
# import data -------------------------------------------------------

# temporarily set the working directory to import from the NetDrive

with_dir(new = '/Volumes/acmelab/1.Resources/2.Arrays/Alberta/OSM/2022-2023',
         
         # make a list of all .csv files in the 2. Timelapse Files folder
         OSM_2022_data <- list.files(
           path = '2. Timelapse Files', # provide the folder/s within the working drive where the files are stored
           pattern = '*\\.csv*', # provide the extension in case there are other files saved in that folder you don't want to load
           full.names = TRUE) %>% 
           
           map_dfr(~.x %>% 
                     read_csv(.,
                              
                              # specify how to read in the various columns, if you don't specify this R reads some of the columns in differently for different files and the code won't work to join them. (Still looking for a more efficient way to do this rather than one-by-one but for now this works)
                              col_types = cols(RootFolder = col_character(),
                                               File = col_character(),
                                               RelativePath = col_character(),
                                               Dark = col_logical(),
                                               DeleteFlag = col_logical(),
                                               Site = col_factor(),
                                               Classifier = col_factor(),
                                               Snow = col_factor(),
                                               Species = col_factor(),
                                               Event = col_character(),
                                               Empty = col_logical(),
                                               CoatColour = col_character(),
                                               CameraMalfunction = col_factor(),
                                               OtherSpecify = col_character(),
                                               Comments = col_character(),
                                               Noteworthy = col_logical(),
                                               DateTime = col_datetime(format = "%Y-%m-%d %H:%M:%S"),
                                               .default = col_integer()))) %>%  #.default sets any unspecified columns to this type
           
           # set the column names to lowercase, this makes it easier to avoid case-sensitive mistakes when coding
           set_names(
             names(.) %>%  
               tolower()))

# finished importing data, this code will return warnings related to 'parsing issues'. Don't panic it is fine.

```

This code will return warnings related to 'parsing issues'. Don't panic, it is fine.


### Timelapse files option 2
This code is probably not that useful but I spent a bit of time figuring out how to make it work before I fixed the code for option 1 so I have kept it here in case it is of use to someone in the future.

This will read in all the data files as separate data frames in a list and name them based on the file names (e.g. the landscape units for 2022-2023 data).

```{r import timelapse data option 2, message=FALSE, warning=FALSE}

# Timelapse files option 2 ----------------------------------------------------------------

# option two: read files in as a list and keep them separated by landscape unit (LU). This is useful if you want to do something with the separate files, but otherwise option one is probably better

# temporarily set the working directory to import from the NetDrive

with_dir(new = '/Volumes/acmelab/1.Resources/2.Arrays/Alberta/OSM/2022-2023',
         
         # make a list of all .csv files in the 2. Timelapse Files folder
         OSM_2022_data_files <- list.files(
           path = '2. Timelapse Files', # provide the folder/s within the working drive where the files are stored
           pattern = '*\\.csv*', # provide the extension in case there are other files saved in that folder you don't want to load
           full.names = TRUE) %>% 
           
           # set the names to the base name of each file w/o the .csv file extension and read in all the files using read_csv 
           {setNames(map(., read_csv), sub("\\.csv$", "", basename(.)))})

```


### Covariate data

These data files have a similar format so we will read them in together using the `map()` function in the *purrr* package. Reminder, the `map()` function let's us perform iterations. The `~x` after the function is a placeholder that refers to the data before the last pipe (e.g. the .csv files we supplied) and all operations within the `map()` will be performed on all of these objects. 

```{r import covariate data}
# Import covariate data ----------------------------------------------------------

# these data files have a similar format so we will read them in together using the map() function in the purrr package

covariate_data <-    
  # provide file path (e.g. folders to find the data)
  file.path('data/raw',
            
            # provide the file names
            c('OSM_LU01_LU13_LU15_LU21_HFI_2022.csv',
              'OSM_LU01_LU13_LU15_LU21_VEG_2022.csv')) %>%
  
  # use purrr map to read in files, the ~.x is a placeholder that refers to the object before the last pipe (aka the list of data we are reading in) so all functions inside the map() after ~.x will be performed on all the objects in the list we provided
  map(~.x %>%
        read_csv(.,
                 
                 # specify how to read in the various columns
                 col_types = cols(Site = col_factor(),
                                  BUFF_DIST = col_integer(),
                                  .default = col_number())) %>%
        
        # set the column names to lower case
        set_names(
          names(.) %>%
            tolower())) %>%
  
  # set the names of the two files in the list outside of the map function, if you don't run this they will be named numerically (e.g. [1], [2]) which can get confusing
  purrr::set_names('HFI',
                   'VEG')

# will get a warning about parsing issues, don't panic it is fine

```


### Deployment data 
Although we could read both of these files in as a list similar to the covariate data, they are more different and I want to perform a few cleaning operations that are different for each during the data import step so it is easier to import them separately

```{r import deployment data}

# Import deployment data --------------------------------------------

# read in data files individually 

# deployment data
deploy <- read_csv('data/raw/OSM_2022_Deployment_Data.csv',
                   
                   # specify how we want the columns read in 
                   col_types = cols(Project.ID = col_factor(),
                                    Deployment.Location.ID = col_factor(),
                                    .default = col_character())
                   # the date columns could be read in as such if we needed but I don't think we use them and the date format is odd to get R to read
                   ) %>% 
  
  # set the column names to lower case and replace the '.' with '_' (these are both personal preferences of mine)
  set_names(
    names(.) %>% 
      tolower() %>% 
      
      # replace the '.' with '_'
      str_replace_all(pattern = '\\.', # provide the character pattern to look for (if you don't keep the \\ it won't work)
                  replacement = '_')) # what you want the pattern to be replaced with


# deployment site data
deploy_sites <- read_csv('data/raw/OSM_2022_Deployment_Site_Data.csv') %>% 
  
  # set the column names to lower case and replace the spaces with '_' (these are both personal preferences of mine)
  set_names(
    names(.) %>% 
      tolower()%>% 
      str_replace_all(pattern = ' ',
                      replacement = '_'))


```


## Data checks timelapse data

This section will likely need to be altered and amended each year as various year-specific issues with the data arise, but the functions in this section offer a good starting point to take a look at the data and ensure things imported correctly.


### Data structure

Check the internal structure of the data using the `str()` function.

This should all be good since we specified how to read in each variable above, but if new columns are added from the Timelapse program/process, that could change things each year so we should double check anyways.
```{r timelapse str}

# check the internal structure
str(OSM_2022_data)

```


### Sites

For 2022-2023 data there should be 155 (there were 156 sites originally but LU01-31 had no data for some reason so we are left with 155). It looks like we have them all based on the number of levels printed with `str()`, but let's make sure there isn't anything wonky with any of the sites.

Since we set site as a factor when we imported the data we can check which sites were imported with the `levels()` function, we can compare this with the deployment data found in '1.Resources/2.Arrays/Alberta/OSM/2022-2023/4. Deployment Data/OSM_2022_Deployment_Data.csv' or [here on the google drive for 2022-2023](https://drive.google.com/drive/u/0/folders/1gEH5eZcDyuoLTzUWAp_Db0kEBJCDD_0t)  

*Will need to change the link with the location of these files each year*

```{r tiemlapse sites}

# check that all the sites are accounted for
# for 2022-2023 data there should be 155 (there were 56 sites originally but LU01-31 had no data)
levels(OSM_2022_data$site) 
# need to fix entry LU 01-71 to LU01-71 (has unnecessary space)

```

Looks like there is one site that was entered with an unnecessary space (LU 01-71), we can convert this to match the format of the others (LU01-71) in the data manipulation section.


### Species names

Let's check that all the species names were entered correctly and we don't have any duplicates with different spelling or something which is common with wildlife data.

Since we set species as a factor when we imported the data we can also use the the `levels()` function to see all the species names.

```{r timelapse species}

# check that all the species names were entered correctly
levels(OSM_2022_data$species)

# no glaring issues with species entries

```


### Check for NAs

There are a lot of NAs in this data set, and most of them are fine but we should check that there aren't NAs for some of the more critical information like the site and datetime columns. We can use the `summary()` function to get a printout of all the variables. 

This is also a great way to check for any other glaring issues such as miscounted groups (really large or really small max/min numbers) etc.

```{r timelapse NAs}

# check for NAs in columns that shouldn't have NAs, looking at the summary is also a good way to check for other issues with the data
summary(OSM_2022_data)

# there is 1 NA in the site column, let's check what other data is associated with this entry to make sure we don't need to remove or fix this entry
OSM_2022_data %>% 
  
  filter(is.na(site))
# it is not an entry with an animal image so I wouldn't worry about fixing the site entry

```

It looks like there was one entry with an NA for the site column but it wasn't associated with an image of an animal so there's really no need to fix it or remove it at this point.


## Data manipulation timelapse data

The following code will fix any data issues we found in the data check steps. This code will need to be modified each year as well as year-specific and R version specific issues arise but this provides a good starting point.

I like to do as much of my data manipulation I can in one *dplyr* pipe (i.e. code chunk) to avoid extra coding and assigning intermediate objects to the environment that I don't need, but if this format doesn't make sense to you, each step can be done individually if you pull the code out of the pipeline and reference the data within each function.

```{r timelapse data manipulation}
# Data manipulation timelapse data -------------------------------------------------

# can add code/remove code within the code chunk below to fix any issues that were found from the data check steps each year

# first make sure to assign an object to the environment that will be your new fixed data. I usually start with a new object (e.g. OSM_2022_data_fixed) as I fiddle with the code to make sure it works and then replace this with the original data name (e.g. OSM_2022_data) and just overwrite the data since I don't want the version with all the issues anyways.
OSM_2022_data_fixed <- OSM_2022_data %>% 
  
  # removed extra columns (see R markdown for info on why these columns got added)
  select(!c(...37,
            dark,
            ...38)) %>% 
  
  # fix site entry with unnecessary space
  mutate(site = recode(site,
                       'LU 01-71' = 'LU01-71')) # old entry followed by new entry


# use code below  to check that each step worked

# columns (removed extra columns w/ NAs)
names(OSM_2022_data_fixed)
 
# sites (fixed LU 01-71)
levels(OSM_2022_data_fixed$site)


```

## Data checks covariate data

### 
