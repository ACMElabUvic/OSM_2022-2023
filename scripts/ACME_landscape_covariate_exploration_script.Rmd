---
title: "ACME_landscape_covariate_exploration_script"
author: "Marissa Dyck"
date: "2024-04-12"
output: 
  html_document:
    theme: journal
    toc: yes
    toc_float: yes
---


The first two chunks of this r markdown file after the r setup allow for plot zooming, but it also means that the html file must be opened in a browser to view the document properly. When it knits in RStudio the preview will appear empty but the html when opened in a browser will have all the info and you can click on each plot to Zoom in on it. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
```

```{css zoom-lib-src, echo = FALSE}
script src = "https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"
```

```{js zoom-jquery, echo = FALSE}
 $(document).ready(function() {
    $('body').prepend('<div class=\"zoomDiv\"><img src=\"\" class=\"zoomImg\"></div>');
    // onClick function for all plots (img's)
    $('img:not(.zoomImg)').click(function() {
      $('.zoomImg').attr('src', $(this).attr('src')).css({width: '100%'});
      $('.zoomDiv').css({opacity: '1', width: 'auto', border: '1px solid white', borderRadius: '5px', position: 'fixed', top: '50%', left: '50%', marginRight: '-50%', transform: 'translate(-50%, -50%)', boxShadow: '0px 0px 50px #888888', zIndex: '50', overflow: 'auto', maxHeight: '100%'});
    });
    // onClick function for zoomImg
    $('img.zoomImg').click(function() {
      $('.zoomDiv').css({opacity: '0', width: '0%'}); 
    });
  });
```

# Before you begin

## Notes

A few notes about this script.

If you are running this with the 2022-2023 data make sure you download the whole (OSM_2022-2023 GitHub repository)[https://github.com/ACMElabUvic/OSM_2022-2023] from the ACMElabUvic GitHub. This will ensure you have all the files, data, and proper folder structure you will need to run this code and associated analyses.

Also make sure you open RStudio through the R project (OSM_2022-2023.Rproj) this will automatically set your working directory to the correct place (wherever you saved the repository) and ensure you don't have to change the file paths for some of the data.

Lastly, if you are looking to adapt this code for a future year of data, you will want to ensure you have run the ACME_camera_script_9-2-2024.R or .Rmd with your data as there is much data formatting, cleaning, and restructuring that has to be done before this code will work.

If you have question please email the most recent author, currently 

Marissa A. Dyck   
Postdoctoral research fellow    
University of Victoria    
School of Environmental Studies     
Email: [marissadyck17@gmail.com](marissadyck17@gmail.com)      

(*update/add authors as needed*)

## Install packages

If you don't already have the following packages installed, use the code below to install them.

```{r install packages, eval=FALSE}

install.packages('tidyverse')
install.packages('PerformanceAnalytics')
install.packages('Hmisc')

```

## Load libraries

Then load the packages to your library.

```{r libraries, message=FALSE}

library(tidyverse) # data tidying, visualization, and much more; this will load all tidyverse packages, can see complete list using tidyverse_packages()
library(PerformanceAnalytics)    #Used to generate a correlation plot
library(Hmisc) # used to generate histograms for all variables in data frame

```


# Read in covariate data

To do any analysis with the detection data from the OSM arrays, we will want to pair it with the covaraite data which has human factors indices (HFI) and landcover data (VEG) for each site. There are a lot of covaraites/features in these datasets that need to be grouped together to be usable, which is what this script covers. 

Let's read in the covariate data (outputs from the ACME_camera_script_9-2-2024.Rmd)

```{r read data}

# model covariates (merged HFI and VEG data from the ACME_camera_script_9-2-2024.R or .Rmd)
covariates <- read_csv('data/processed/OSM_2022_covariates.csv',
                       
                       # set the column types to read in correctly
                       col_types = cols(array = col_factor(),
                                        camera = col_factor(),
                                        site = col_factor(),
                                        buff_dist = col_factor(),
                                        .default = col_number()))

# check variable structure
str(covariates)

```

# Data exploration

There are too many covariates to include in the models individually and many of them describe similar HFI features. 

> Now that this section is finalized, we will use the structure outlined in the covariates_table.docx which can be found in the 'relevant_literature' folder of this repository for formatting the covariates for this and future related analyses. However, the code below outlines a process to explore the data which led to some of the decisions in the covariates_table.docx in case someone wants to group the data in a different way they have code to explore it


The covariate_table and the README file in this repository include descriptions of each feature from 
the [ABMI human footprints wall to wall data download website for Year 2021](https://abmi.ca/home/data-analytics/da-top/da-product-overview/Human-Footprint-Products/HF-inventory.html); which can also be found in the relevant_literature folder of this repository (HFI_2021_v1_0_Metadata_Final.pdf).

## Order data

First lets order the columns alphabetically so we can look at descriptions for everything in the ABMI doc easier. We will want the non-covariate columns (i.e., array, site, camera, buffer_dsit) at the front so we can use relocate after we order all of the columns to move these four to the front of the data.

```{r order covs}

covariates <- covariates %>% 
  
  # order columns alphabetically
  select(order(colnames(.))) %>% 
  
  # we want to move the columns that aren't HFI features or landcover to the front
  relocate(.,
           c(array,
             site,
             camera,
             buff_dist))  

# get a list of column names to ensure it worked
names(covariates)
```
## Summary 1000m

Let's get a summary of each variable now, and lets filter by just the 1000m buffer width so we don't have a bunch of repeated data for each buffer width at each site, this will give us general insights into how much variability we have with each feature at a general buffer width. *You can change this if you are interested in a different bufffer width specifically, or if it makes more since to see the data for the min (250m) or max (5000m) buffer width.

```{r covs summary}

covariates %>% 
  # filter to just buffer 1000 m
  filter(buff_dist == 1000) %>% 
  
  summary(.)
```

## Histograms 1000m

Let's also plot histograms of each variable for data visualization in a for loop, I wanted to do this for just one buffer size to reduce replicates but it will also drop any variables for which all the data are zeros, so you could explore this at different buffer widths or just remove the filter function and look at all the data which is what I do below once it is grouped

```{r covs histograms}

# filter to just one buffer width

covariates_1000 <- covariates %>%  
  
  filter(buff_dist == 1000)

for (col in 1:ncol(covariates_1000)) {
    hist(covariates_1000[,col])
}
```

Now we can use the information from the previous few steps as well as the variable descriptions from the [ABMI human footprints wall to wall data download website for Year 2021](https://abmi.ca/home/data-analytics/da-top/da-product-overview/Human-Footprint-Products/HF-inventory.html) which is stored in the 'relevant literature' portion of this document **AND** also copied into the README file, to group the covariates so we reduce the number of potential variables to explore in the modeling phase. 

# Format covariates

## Group covaraites

We will use the `mutate()` function with some tidyverse trickery (i.e., nesting `across()` and `contains()` in `rowsums()`) to sum across each observation (row) by searching for various character strings. If there isn't a common character string for multiple variables we want to sum then we provide each one individually. We can also combine these methods (e.g., with 'facilities' [see code]).

```{r format covs}

covariates_grouped <- covariates %>% 
  
  # rename 'vegetated_edge_roads so that we can use road as keyword to group roads without including this feature
  rename('vegetated_edge_rds' = vegetated_edge_roads) %>% 
  
  # within the mutate function create new column names for the grouped variables
  mutate(
    # borrowpits
    borrowpits = rowSums(across(contains('borrowpit'))) + # here we use rowsums with across() and contains() to sum acrross each row any values for columns that contain the keyword above. Be careful when using that there aren't any variables that match the string (keyword) provided that you don't want to include!
      
      dugout +
      lagoon +
      sump,
    
    
    # clearings
    clearings = rowSums(across(contains('clearing'))) +
      runway,
    
    # cultivations
    cultivation = crop + 
      cultivation_abandoned +
      fruit_vegetables +
      rough_pasture +
      tame_pasture,
    
    # harvest areas
    harvest = rowSums(across(contains('harvest'))),
    
    # industrial facilities
    facilities = rowSums(across(contains('facility'))) +
      rowSums(across(contains('plant'))) +
      camp_industrial +
      mill +
      ris_camp_industrial +
      ris_tank_farm +
      ris_utilities +
      urban_industrial,
    
    # mine areas
    mines = rowSums(across(contains('mine'))) +
      rowSums(across(contains('tailing'))) +
      grvl_sand_pit +
      peat +
      ris_drainage +
      ris_oilsands_rms +
      ris_overburden_dump +
      ris_reclaim_ready +
      ris_soil_salvaged +
      ris_waste,
    
    # railways
    railways = rowSums(across(contains('rlwy'))),
    
    # reclaimed areas
    reclaimed = rowSums(across(contains('reclaimed'))) +
      ris_soil_replaced +
      ris_windrow,
    
    # recreation areas
    recreation = campground +
      golfcourse +
      greenspace +
      recreation,
    
    # residential areas (can't use residence as keyword because 'residence_clearing' is in clearing unless we rearrange groupings or rename that one)
    residential = country_residence +
      rural_residence +
      urban_residence,
    
    # roads (we renamed 'vegetated_edge_roads' above to 'vegetated_edge_rds' so we can use roads as keyword here which saves a bunch of coding as there are many many road variables)
    roads = rowSums(across(contains('road'))) +
      interchange_ramp +
      airp_runway +
      ris_airp_runway +
      transfer_station,
    
    # seismic lines
    seismic_lines = conventional_seismic,
    
    # 3D sesimic lines
    seismic_lines_3D = low_impact_seismic,
    
    # transmission lines
    transmission_lines = rowSums(across(contains('transmission'))),
    
    # trails
    trails = rowSums(across(contains('trail'))),
    
    # vegetated edges
    veg_edges = rowSums(across(contains('vegetated'))) +
      surrounding_veg,
    
    # man-made water features
    water = canal +
      reservoir,
    
    # well sites (this probably includes 'clearing_wellpad' need to check)
    wells = rowSums(across(contains('well'))),
    
    # remove columns that were used to create new columns to tidy the data frame
         .keep = 'unused') %>% 
  
  # reorder variables so the veg data is after all the HFI data
  relocate(starts_with('lc_class'),
           .after = wells)

# see what's left
names(covariates_grouped)

# check the structure of new data
str(covariates_grouped)

# check summary of new data
summary(covariates_grouped)

# there are some NAs in the data which will cause problems with modeling/visualization of data ignore for now but will explore these sites specifically after report

covariates_grouped <- covariates_grouped %>% 
  
  # remove rows with NAs
  na.omit()

```


## Grouped histograms

Let's look at the histograms again and see if we need to remove any features or feature groups without enough data

```{r covs grouped histograms}

# use for loop to plot histograms for all covariates

for (col in 5:ncol(covariates_grouped)) {
    hist(covariates_grouped[,col])
}
```
> IMO we don't have enough variation in data to use the following features/feature groups

* cfo     
* Cultivation   
* Reclaimed   
* Recreation    
* Reservoir   
* Residential 
* Water
* lc_class_20 (aka water)   
* lc_class120 (aka agriculture)
* lc_class32 (aka rocks and rubble) 
* lc_class33 (aka exposed land)   

We also don't have any data for following features since they don't plot with the `hist()` function

* Landfill  
* railways

Also, there's not a lot of data for the following features, which are similar and of interest to OSM, so in the past they've been grouped together and we will here as well

* Borrowpits    
* Clearings   
* Facilities    
* Mines


## Format covariates further

So let's modify this data and remove those features for now **this step will need to be changed each year likely**

Let's also rename the landcover classes so they make more sense without having to look them up by number (*maybe should add this to script earlier for next year*)
```{r covs remove features}

covariates_grouped <- covariates_grouped %>% 
  
  # create column osm_industrial
  mutate(
    osm_industrial = borrowpits +
    clearings +
    facilities +
    mines,
    
    # remove columns we used to make this variable
    .keep = 'unused') %>% 
  
  # remove other features we don't need
  select(!c(cfo,
            cultivation,
            reclaimed,
            recreation,
            residential,
            water,
            lc_class20,
            lc_class120,
            lc_class32,
            lc_class33,
            landfill,
            railways)) %>%
  
  # rename landcover classes
  rename(
    grassland = lc_class110,
    coniferous = lc_class210,
    broadleaf = lc_class220,
    mixed = lc_class230,
    developed = lc_class34,
    shrub = lc_class50) 

# check that it worked
names(covariates_grouped)
```

## Subset data by buffer

We need to subset the data so we have separate data frames for each buffer width to work with in the analysis **AND** to explore correlation between variables at each buffer width, as these may very with spatial scales

Let's use a for loop to subset the data
```{r subset data}
buffer_frames <- list()

for (i in unique(covariates_grouped$buff_dist)){
  
  print(i)
  
  # Subset data based on radius
  df <- covariates_grouped %>%
    filter(buff_dist == i)
  
  # list of dataframes
  buffer_frames <-c (buffer_frames, list(df))
}

# name list objects so we can extract names for plotting 

buffer_frames <- buffer_frames %>% 
  
  # absurdly long way to do this but for sake of time fuck it
  purrr::set_names('250 meter buffer',
                   '500 meter buffer',
                   '750 meter buffer',
                   '1000 meter buffer',
                   '1250 meter buffer',
                   '1500 meter buffer',
                   '1750 meter buffer',
                   '2000 meter buffer',
                   '2250 meter buffer',
                   '2500 meter buffer',
                   '2750 meter buffer',
                   '3000 meter buffer',
                   '3250 meter buffer',
                   '3500 meter buffer',
                   '3750 meter buffer',
                   '4000 meter buffer',
                   '4250 meter buffer',
                   '4500 meter buffer',
                   '4750 meter buffer',
                   '5000 meter buffer')
```

Now we have a list with data frames for each buffer width which we can work with later. 


# Autocorellation

## Correlation plots

Now we need to make correlation plots for each buffer width to see what variables are correlated at a given spatial scale. We can use `purrr::map()` with the `chart.Correlation()` function from the *PerformanceAnalytics* package to make correlation plots with a specified method (e.g., pearson, spearman, etc.) That also show histograms and scatterplots of each variable.

```{r correlation plots pearson, warning=FALSE}

correlation_plots <- buffer_frames %>% 
  
  purrr::map(
    ~.x %>% 
      
      # select numeric variables only since we can't compute a r2 for non-numeric
      select_if(is.numeric) %>% 
      
      # use chart.correlation in
      chart.Correlation(.,
                        histogram = TRUE, 
                        method = "pearson")
  )
```

## Correlation table


## 250m

There is a section for each buffer width outlining the variables that are autocorrelated and thus should not be included in the same model, it includes the r2 as well

* roads & LC

## 500m


## Exploratory plots

> add more to this section in later when we have more time to explore the covariates and choose which should be inlcuded etc.

```{r hfi histograms, eval=FALSE}

# use this code to change figure margins otherwise will not plot because figure margines are too large
par(mar=c(1,1,1,1))

# now use purrr to plot histograms for all remaining HFI variables for each buffer
hfi_histograms <- buffer_frames %>% 
  
  purrr::imap(
    ~.x %>% 
      
      # filter to just the HFI variables 
      select(where(is.numeric) &
          ! starts_with('lc_class')) %>% 
      
      # pipe into hist.data.frame function to make histograms for each variable
      hist.data.frame(mtitl = paste0('Histograms of HFI variables at ', .y)))


```



Now let's do the same thing with the landcover variables

```{r lc histograms, eval=FALSE}

lc_histograms <- buffer_frames %>% 
  
  purrr::imap(
    ~.x %>% 
      
      # filter to just the landcover variables 
      select(where(is.numeric) &
          starts_with('lc_class')) %>% 
      
      # pipe into hist.data.frame function to make histograms for each variable
      hist.data.frame(mtitl = paste0('Histograms of landcover variables at ', .y)))
```
